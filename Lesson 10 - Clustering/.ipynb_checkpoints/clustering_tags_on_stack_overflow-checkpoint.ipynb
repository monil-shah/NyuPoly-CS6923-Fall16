{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow - Clustering\n",
    "\n",
    "This notebook starts exploring the data of the Kaggle Stack Overflow question competition.\n",
    "The competition is here: https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow\n",
    "\n",
    "The goal was to build a classifier that redicts whether or not a question will be closed given the question as submitted.\n",
    "\n",
    "Let's see if clustering would be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/ruben/Downloads/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "One obvious candidate for clustering would be the vast amount of tags we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 49.4 ms, total: 5.29 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['tags'] = data.apply(lambda x: \" \".join(set(str(x['Tag%d' % i]) for i in xrange(1, 6))), axis=1)\n",
    "data['tags'] = data['tags'].str.replace('nan', '').str.replace(\"  \", \" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 18309 tags.\n"
     ]
    }
   ],
   "source": [
    "tags = set([tag for tags in data.tags.values for tag in tags.split()])\n",
    "print \"We have\", len(tags), \"tags.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot. We could maybe cluster these, and then feed the cluster category into the model, rather than an ID for one of the 18K tags.  We could use `CountVectorizer` for this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "# N = 10000  # only use the first N documents for clustering (to speed up computations)\n",
    "# data = data.iloc[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 950 ms, sys: 16.5 ms, total: 966 ms\n",
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000, min_df=10, max_df=.95, binary=True)\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering tags by their documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XT = X.T\n",
    "XT = StandardScaler().fit_transform(XT.toarray().astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 13.2 s, total: 4min 48s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([   1, 3224,    2,    1,    1,    1,    1,    1,    2,    1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(XT), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that didn't quite work: almost all tags got into one cluster, and the other clusters just got one tag. (Note we have less tags since we only used part of the data.)\n",
    "\n",
    "#### Clustering documents by their tags\n",
    "\n",
    "One other way we could do, is clustering the documents according to their tags, and then use their document cluster to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 s, sys: 90.5 ms, total: 35.5 s\n",
      "Wall time: 35.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=10, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruben/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:862: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
      "  X = self._check_test_data(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([12219, 79839,  7798,  4213,  2353,  3632, 10093,  2864,  5398, 11863]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(X), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Let's inspect the most common tags in these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 tags per cluster:\n",
      "Cluster 0: php mysql html javascript php5 jquery arrays ajax wordpress codeigniter database sql\n",
      "Cluster 1: android python jquery html css mysql google visual ios facebook web objective\n",
      "Cluster 2: javascript jquery html css ajax php html5 google js events internet json\n",
      "Cluster 3: sql server 2008 database mysql net 2005 tsql query linq asp oracle\n",
      "Cluster 4: linux ubuntu kernel unix bash shell php java command python networking ssh\n",
      "Cluster 5: ruby rails activerecord python jquery heroku php mysql rubygems rspec ajax javascript\n",
      "Cluster 6: net asp mvc vb visual jquery studio javascript web ajax framework entity\n",
      "Cluster 7: windows phone net xp server visual linux 2008 silverlight services java mobile\n",
      "Cluster 8: iphone objective ios xcode ipad sdk cocoa touch ios5 uitableview core app\n",
      "Cluster 9: java android ee eclipse swing web spring xml hibernate php jsp javascript\n"
     ]
    }
   ],
   "source": [
    "top = 12\n",
    "print \"Top %d tags per cluster:\" % top\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = cv.get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :top]:\n",
    "        print terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are at least a front-end cluster, a database cluster, and a mobile cluster.  Note that, since we clustered documents, not tags, a tag might be associated with several clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD9CAYAAAC7iRw+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni1+SOsbil6SOsfglqWMsfknqmP8P3JnvSMgkJNoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110c793d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['tag_cluster'] = model.predict(X)\n",
    "s = data.groupby('tag_cluster').OpenStatus.mean().sort(inplace=False)\n",
    "f = s.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in closed posts per cluster suggests we could try extracting some value from this.  We leave it as an exercise to verify if adding these clusters to your feature matrix indeed leads to a higher preduction accuracy.\n",
    "\n",
    "#### Jaccard distance\n",
    "\n",
    "The [_Jaccard index_](https://en.wikipedia.org/wiki/Jaccard_index) is a similarity metric between text documents. It measures how many words two documents have in common, as a fraction of the total number of distinct words in both documents.\n",
    "\n",
    "$$\\text{Jaccard index} = \\frac{ |A \\cap B | }{ |A \\cup B| }$$\n",
    "\n",
    "We could make a Jaccard matrix $J$, with pairwise similarities $J_{ij}$ as entries.\n",
    "- `J[i, j]` = Jaccard similarity between doc _i_ and _j_ (between 0 and 1)\n",
    "- `J[i, i]` = 1, obviously, and\n",
    "- `J[i, j]` = `J[i, j]`, i.e., the matrix is symmetric.\n",
    "\n",
    "We could also define the _Jaccard distance_, which has $D_{ii} = 0$ for identical documents, and bigger values as the documents have less words in common.  We define: $D = 1 - J,$ which has values between 0 and 1.\n",
    "\n",
    "We could also use this for comparing our tags: how many documents do two tages have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 911 ms, sys: 18.8 ms, total: 930 ms\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000,\n",
    "                     min_df=10, max_df=.95, binary=True)  # binary=True is important!\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Jaccard matrix and the distance matrix.\n",
    "\n",
    "Note that we could compute\n",
    "\n",
    "    U = [[n_docs[i] + n_docs[j] - I[i, j] for i in xrange(n_tags)] \n",
    "         for j in xrange(n_tags)]  # this is slow\n",
    "\n",
    "but that is very slow. We use `numpy`'s vectorization and broadcasting instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tags = X.shape[1]  # number of tags\n",
    "I = X.T.dot(X).toarray()  # X-transposed times X gives a tag x tag matrix with the # of docs in common\n",
    "n_docs = np.diag(I)  # number of docs per tag\n",
    "N = n_docs.reshape(n_tags, 1) * np.ones(n_tags)  # number of docs broadcasted over the entire row\n",
    "U = N + N.T - I  # total distinct docs = n_docs_i + n_docs_j - words in common\n",
    "J = I / U.astype(float)\n",
    "D = 1 - J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a few random tags and see what the closest tags are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paste             : paste copy cut clipboard pdt filepath filenames neo4j contextmenu vi\n",
      "subclass          : subclass nib uilabel nsoperation covariance nsview extends nstableview pointer generic\n",
      "tail              : tail recursion finite factorial best ocaml state append distribution logging\n",
      "thrift            : thrift buffers protocol asio rpc weblogic cassandra agile compatibility boost\n",
      "fragment          : fragment identifier changes orientation mapview honeycomb adapter osgi escaping state\n",
      "launch            : launch condition installshield manifest orientation components purchase exe timeout device\n",
      "fiddler           : fiddler firebug localhost playframework https proxy cookies firefox session post\n",
      "arm               : arm embedded vlc microcontroller cpu floating x86 pi avr nfs\n",
      "ajax              : ajax jquery javascript json asp php mvc net html forms\n",
      "entitymanager     : entitymanager jpa ejb nullpointerexception hibernate generics netbeans entity spring java\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "tags = np.array(cv.get_feature_names())\n",
    "for no in np.random.choice(n_tags, top, replace=False):  # pick 10 random tags\n",
    "    print \"%-18s:\" % tags[no], \" \".join(tags[D[no].argsort()[:top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense. Some tags have more meaning than others, I expect. Note that this is not a partitioning, as we only have a distance between words.\n",
    "\n",
    "We could also apply `KMeans` to this Jaccard matrix, as the entries are indeed distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tags per cluster:\n",
      "Cluster 0: objective iphone ios cocoa touch xcode memory ipad ios5 leaks\n",
      "Cluster 1: studio visual 2010 castle source windsor protocol buffers setter getter\n",
      "Cluster 2: internet machine js explorer computer intelligence questions interview coding mod\n",
      "Cluster 3: processing gd image manipulation parallel transparency bit png imagemagick alpha\n",
      "Cluster 4: exc bad array multidimensional access casting overloading interface type operator\n",
      "Cluster 5: cream sandwich ice honeycomb softkeyboard decompiling launcher spinner htc fullscreen\n",
      "Cluster 6: command ruby line amazon programming rails bash scripting shell languages\n",
      "Cluster 7: asp net binding dependency wpf mvc mvvm injection data xaml\n",
      "Cluster 8: latitude longitude area gprs distance circle spatial polygon mapkit coordinates\n",
      "Cluster 9: intellij idea server sql google tips tricks engine dynamics crm\n"
     ]
    }
   ],
   "source": [
    "model.fit(D)\n",
    "print \"Top %d tags per cluster:\" % top\n",
    "order_centroids = model.cluster_centers_.argsort()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % i, \" \".join(tags[order_centroids[i, :top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite promising.\n",
    "\n",
    "Unfortunately, the model has put a lot of tags into the same cluster again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([  37,   92, 2669,   35,   84,    3,  176,   28,    2,  109]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(D), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## Exercise\n",
    "- Add the cluster information to your feature set and train a model on your data. Does the inclusion of these clusters indeed imporve prediction accuracy?  (Don't forget to cross-validate.)\n",
    "- Try different values for `n_clusters` and see if you could find a good value using the _elbow method_.\n",
    "- We have looked at clustering tags by documents, clustering documents by tags, and at the Jaccard distance between two tags using the number of documents they have in common.  Could you think of other ways of clustering tags or documents?  Try to implement these and see how effective they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
