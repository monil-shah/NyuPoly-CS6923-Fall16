{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow - Clustering\n",
    "\n",
    "This notebook starts exploring the data of the Kaggle Stack Overflow question competition.\n",
    "The competition is here: https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow\n",
    "\n",
    "The goal was to build a classifier that redicts whether or not a question will be \"closed\" given the question as submitted.\n",
    "Questions can be closed because they are: \"off-topic\", \"unclear\", \"too broad\" or \"opinion based\". There is also \"duplicate\" but that has been omitted from the data set. Currently 6% of the questions endup closed. \n",
    "\n",
    "In this first pass, we will see if clustering would be helpful. If time permits, we will run the competition next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140272, 14)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train-sample.csv\", index_col=0)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PostId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6046168</th>\n",
       "      <td>05/18/2011 14:14:05</td>\n",
       "      <td>543315</td>\n",
       "      <td>09/17/2010 10:15:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>I am building a corpus of indexed sentences in...</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873911</th>\n",
       "      <td>02/02/2011 11:30:10</td>\n",
       "      <td>465076</td>\n",
       "      <td>10/03/2010 09:30:58</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>i create a xml document with JAXP and search a...</td>\n",
       "      <td>dom</td>\n",
       "      <td>xsd</td>\n",
       "      <td>jaxp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n",
       "PostId                                                           \n",
       "6046168  05/18/2011 14:14:05       543315  09/17/2010 10:15:06   \n",
       "4873911  02/02/2011 11:30:10       465076  10/03/2010 09:30:58   \n",
       "\n",
       "         ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "PostId                                                                   \n",
       "6046168                         1                                    2   \n",
       "4873911                       192                                   24   \n",
       "\n",
       "                                                     Title  \\\n",
       "PostId                                                       \n",
       "6046168  For Mongodb is it better to reference an objec...   \n",
       "4873911  How to insert schemalocation in a xml document...   \n",
       "\n",
       "                                              BodyMarkdown     Tag1 Tag2  \\\n",
       "PostId                                                                     \n",
       "6046168  I am building a corpus of indexed sentences in...  mongodb  NaN   \n",
       "4873911  i create a xml document with JAXP and search a...      dom  xsd   \n",
       "\n",
       "         Tag3 Tag4 Tag5 PostClosedDate OpenStatus  \n",
       "PostId                                             \n",
       "6046168   NaN  NaN  NaN            NaN       open  \n",
       "4873911  jaxp  NaN  NaN            NaN       open  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has the following features\n",
    "- PostId - ID number of the question\n",
    "- PostCreationDate - Date and time the question was asked\n",
    "- OwnerUserId - ID number of the question asker\n",
    "- OwnerCreationDate - Date and time the question asker's account was created\n",
    "- ReputationAtPostCreation - Reputation of the question asker at the time the question was asked\n",
    "- OwnerUndeletedAnswerCountAtPostTime - Number of answers (to other questions) that the question asker had written at the time the question was asked\n",
    "- Title - Title of the question\n",
    "- BodyMarkdown - Body of the question\n",
    "- Tag1 through Tag5 - Topical tags applied to the question\n",
    "- PostClosedDate - Date and time the question was closed (if it was closed; not in test set)\n",
    "- OpenStatus - 1 indicates open, 0 indicates closed (to be predicted in test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "One obvious candidate for clustering would be the vast amount of tags we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['tags'] = data.apply(lambda x: \" \".join(set(str(x['Tag%d' % i]) for i in range(1, 6))), axis=1)\n",
    "data['tags'] = data['tags'].str.replace('nan', '').str.replace(\"  \", \" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 18309 tags.\n"
     ]
    }
   ],
   "source": [
    "tags = set([tag for tags in data.tags.values for tag in tags.split()])\n",
    "print (\"We have\", len(tags), \"tags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot. We could maybe cluster these, and then feed the cluster category into the model, rather than an ID for one of the 18K tags.  We could use `CountVectorizer` for this. Remember that 'CountVectorizer' converts a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "# N = 10000  # only use the first N documents for clustering (to speed up computations)\n",
    "# data = data.iloc[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix.\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000, min_df=10, max_df=.95, binary=True)\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering tags by their documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<140272x3235 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 387519 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667],\n",
       "       [-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667],\n",
       "       [-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667],\n",
       "       ..., \n",
       "       [-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667],\n",
       "       [-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667],\n",
       "       [-0.0175845 , -0.02487208, -0.03934447, ..., -0.02487208,\n",
       "        -0.03046667, -0.03046667]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XT = X.T\n",
    "XT = StandardScaler().fit_transform(XT.toarray().astype(float))\n",
    "XT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([   1, 3224,    1,    1,    1,    1,    1,    1,    1,    3], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(XT), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that didn't quite work: almost all tags got into one cluster, and the other clusters just got one tag. (Note we have less tags since we only used part of the data.)\n",
    "\n",
    "#### Clustering documents by their tags\n",
    "\n",
    "One other way we could do, is clustering the documents according to their tags, and then use their document cluster to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([  300, 10180, 12392,  1821,  5676,  7338, 11996,  3650, 82943,  3976], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(X), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Let's inspect the most common tags in these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 tags per cluster:\n",
      "Cluster 0:\n",
      "coding\n",
      "style\n",
      "java\n",
      "php\n",
      "css\n",
      "design\n",
      "code\n",
      "net\n",
      "conventions\n",
      "javascript\n",
      "python\n",
      "naming\n",
      "\n",
      "Cluster 1:\n",
      "net\n",
      "asp\n",
      "mvc\n",
      "vb\n",
      "sql\n",
      "jquery\n",
      "server\n",
      "javascript\n",
      "web\n",
      "ajax\n",
      "linq\n",
      "framework\n",
      "\n",
      "Cluster 2:\n",
      "php\n",
      "mysql\n",
      "html\n",
      "javascript\n",
      "php5\n",
      "jquery\n",
      "arrays\n",
      "ajax\n",
      "codeigniter\n",
      "wordpress\n",
      "sql\n",
      "database\n",
      "\n",
      "Cluster 3:\n",
      "visual\n",
      "studio\n",
      "2010\n",
      "net\n",
      "2008\n",
      "asp\n",
      "windows\n",
      "sql\n",
      "vb\n",
      "2005\n",
      "server\n",
      "debugging\n",
      "\n",
      "Cluster 4:\n",
      "iphone\n",
      "objective\n",
      "ios\n",
      "xcode\n",
      "ipad\n",
      "sdk\n",
      "cocoa\n",
      "touch\n",
      "ios5\n",
      "uitableview\n",
      "core\n",
      "android\n",
      "\n",
      "Cluster 5:\n",
      "javascript\n",
      "jquery\n",
      "html\n",
      "ajax\n",
      "html5\n",
      "google\n",
      "css\n",
      "php\n",
      "js\n",
      "events\n",
      "json\n",
      "internet\n",
      "\n",
      "Cluster 6:\n",
      "java\n",
      "android\n",
      "ee\n",
      "eclipse\n",
      "swing\n",
      "web\n",
      "spring\n",
      "xml\n",
      "hibernate\n",
      "jsp\n",
      "php\n",
      "javascript\n",
      "\n",
      "Cluster 7:\n",
      "ruby\n",
      "rails\n",
      "activerecord\n",
      "python\n",
      "jquery\n",
      "heroku\n",
      "mysql\n",
      "php\n",
      "rubygems\n",
      "rspec\n",
      "ajax\n",
      "javascript\n",
      "\n",
      "Cluster 8:\n",
      "android\n",
      "python\n",
      "sql\n",
      "jquery\n",
      "windows\n",
      "linux\n",
      "server\n",
      "mysql\n",
      "google\n",
      "database\n",
      "facebook\n",
      "web\n",
      "\n",
      "Cluster 9:\n",
      "html\n",
      "css\n",
      "jquery\n",
      "javascript\n",
      "internet\n",
      "explorer\n",
      "html5\n",
      "css3\n",
      "php\n",
      "div\n",
      "browser\n",
      "image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = 12\n",
    "print (\"Top %d tags per cluster:\" % top)\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = cv.get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    print (\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :top]:\n",
    "        print (terms[ind]),\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are at least a front-end cluster, a database cluster, and a mobile cluster.  Note that, since we clustered documents, not tags, a tag might be associated with several clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId\n",
       "6046168     8\n",
       "4873911     8\n",
       "3311559     8\n",
       "9990413     2\n",
       "10421966    8\n",
       "8616154     8\n",
       "1520973     5\n",
       "5528942     8\n",
       "4344698     8\n",
       "7910832     8\n",
       "11610237    8\n",
       "9131744     8\n",
       "2047987     8\n",
       "8341885     5\n",
       "11200627    1\n",
       "6984871     8\n",
       "8589517     8\n",
       "8784855     3\n",
       "8548243     8\n",
       "5182954     8\n",
       "4306229     8\n",
       "6508144     8\n",
       "11157471    8\n",
       "7852524     1\n",
       "11330139    8\n",
       "10912452    8\n",
       "2037737     8\n",
       "7489468     8\n",
       "7039786     8\n",
       "4563508     5\n",
       "           ..\n",
       "8252258     8\n",
       "5660600     1\n",
       "6757001     1\n",
       "10471141    8\n",
       "8965603     6\n",
       "2021996     2\n",
       "11069552    8\n",
       "3091804     8\n",
       "4518655     6\n",
       "9312476     6\n",
       "11722379    8\n",
       "1528        8\n",
       "6632262     9\n",
       "7411454     8\n",
       "6132175     8\n",
       "8084479     8\n",
       "4986674     8\n",
       "4498482     5\n",
       "7821639     8\n",
       "7678462     8\n",
       "11006475    8\n",
       "7437964     1\n",
       "5320699     2\n",
       "9127782     8\n",
       "11487517    6\n",
       "2982729     8\n",
       "8809105     7\n",
       "10674791    1\n",
       "3997045     9\n",
       "11570849    2\n",
       "Name: tag_cluster, dtype: int32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag_cluster'] = model.predict(X)\n",
    "data.tag_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#s = data.groupby('tag_cluster', 'open').OpenStatus.mean().sort(inplace=False)\n",
    "#f = s.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in closed posts per cluster suggests we could try extracting some value from this.  We leave it as an exercise to verify if adding these clusters to your feature matrix indeed leads to a higher preduction accuracy.\n",
    "\n",
    "#### Jaccard distance\n",
    "\n",
    "The [_Jaccard index_](https://en.wikipedia.org/wiki/Jaccard_index) is a similarity metric between text documents. It measures how many words two documents have in common, as a fraction of the total number of distinct words in both documents.\n",
    "\n",
    "$$\\text{Jaccard index} = \\frac{ |A \\cap B | }{ |A \\cup B| }$$\n",
    "\n",
    "We could make a Jaccard matrix $J$, with pairwise similarities $J_{ij}$ as entries.\n",
    "- `J[i, j]` = Jaccard similarity between doc _i_ and _j_ (between 0 and 1)\n",
    "- `J[i, i]` = 1, obviously, and\n",
    "- `J[i, j]` = `J[i, j]`, i.e., the matrix is symmetric.\n",
    "\n",
    "We could also define the _Jaccard distance_, which has $D_{ii} = 0$ for identical documents, and bigger values as the documents have less words in common.  We define: $D = 1 - J,$ which has values between 0 and 1.\n",
    "\n",
    "We could also use this for comparing our tags: how many documents do two tages have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 911 ms, sys: 18.8 ms, total: 930 ms\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000,\n",
    "                     min_df=10, max_df=.95, binary=True)  # binary=True is important!\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Jaccard matrix and the distance matrix.\n",
    "\n",
    "Note that we could compute\n",
    "\n",
    "    U = [[n_docs[i] + n_docs[j] - I[i, j] for i in xrange(n_tags)] \n",
    "         for j in xrange(n_tags)]  # this is slow\n",
    "\n",
    "but that is very slow. We use `numpy`'s vectorization and broadcasting instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tags = X.shape[1]  # number of tags\n",
    "I = X.T.dot(X).toarray()  # X-transposed times X gives a tag x tag matrix with the # of docs in common\n",
    "n_docs = np.diag(I)  # number of docs per tag\n",
    "N = n_docs.reshape(n_tags, 1) * np.ones(n_tags)  # number of docs broadcasted over the entire row\n",
    "U = N + N.T - I  # total distinct docs = n_docs_i + n_docs_j - words in common\n",
    "J = I / U.astype(float)\n",
    "D = 1 - J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a few random tags and see what the closest tags are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paste             : paste copy cut clipboard pdt filepath filenames neo4j contextmenu vi\n",
      "subclass          : subclass nib uilabel nsoperation covariance nsview extends nstableview pointer generic\n",
      "tail              : tail recursion finite factorial best ocaml state append distribution logging\n",
      "thrift            : thrift buffers protocol asio rpc weblogic cassandra agile compatibility boost\n",
      "fragment          : fragment identifier changes orientation mapview honeycomb adapter osgi escaping state\n",
      "launch            : launch condition installshield manifest orientation components purchase exe timeout device\n",
      "fiddler           : fiddler firebug localhost playframework https proxy cookies firefox session post\n",
      "arm               : arm embedded vlc microcontroller cpu floating x86 pi avr nfs\n",
      "ajax              : ajax jquery javascript json asp php mvc net html forms\n",
      "entitymanager     : entitymanager jpa ejb nullpointerexception hibernate generics netbeans entity spring java\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "tags = np.array(cv.get_feature_names())\n",
    "for no in np.random.choice(n_tags, top, replace=False):  # pick 10 random tags\n",
    "    print \"%-18s:\" % tags[no], \" \".join(tags[D[no].argsort()[:top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense. Some tags have more meaning than others, I expect. Note that this is not a partitioning, as we only have a distance between words.\n",
    "\n",
    "We could also apply `KMeans` to this Jaccard matrix, as the entries are indeed distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tags per cluster:\n",
      "Cluster 0: objective iphone ios cocoa touch xcode memory ipad ios5 leaks\n",
      "Cluster 1: studio visual 2010 castle source windsor protocol buffers setter getter\n",
      "Cluster 2: internet machine js explorer computer intelligence questions interview coding mod\n",
      "Cluster 3: processing gd image manipulation parallel transparency bit png imagemagick alpha\n",
      "Cluster 4: exc bad array multidimensional access casting overloading interface type operator\n",
      "Cluster 5: cream sandwich ice honeycomb softkeyboard decompiling launcher spinner htc fullscreen\n",
      "Cluster 6: command ruby line amazon programming rails bash scripting shell languages\n",
      "Cluster 7: asp net binding dependency wpf mvc mvvm injection data xaml\n",
      "Cluster 8: latitude longitude area gprs distance circle spatial polygon mapkit coordinates\n",
      "Cluster 9: intellij idea server sql google tips tricks engine dynamics crm\n"
     ]
    }
   ],
   "source": [
    "model.fit(D)\n",
    "print \"Top %d tags per cluster:\" % top\n",
    "order_centroids = model.cluster_centers_.argsort()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % i, \" \".join(tags[order_centroids[i, :top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite promising.\n",
    "\n",
    "Unfortunately, the model has put a lot of tags into the same cluster again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([  37,   92, 2669,   35,   84,    3,  176,   28,    2,  109]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(D), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## Exercise\n",
    "- Add the cluster information to your feature set and train a model on your data. Does the inclusion of these clusters indeed imporve prediction accuracy?  (Don't forget to cross-validate.)\n",
    "- Try different values for `n_clusters` and see if you could find a good value using the _elbow method_.\n",
    "- We have looked at clustering tags by documents, clustering documents by tags, and at the Jaccard distance between two tags using the number of documents they have in common.  Could you think of other ways of clustering tags or documents?  Try to implement these and see how effective they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
